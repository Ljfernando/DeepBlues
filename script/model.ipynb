{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list = os.listdir('../recoded_songs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = pd.read_csv('../recoded_songs/Apex_Blues_A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_S</td>\n",
       "      <td>Ia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F_L</td>\n",
       "      <td>Ia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G_S</td>\n",
       "      <td>Ia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gb_L</td>\n",
       "      <td>Ia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_S</td>\n",
       "      <td>Ia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state section\n",
       "0   E_S      Ia\n",
       "1   F_L      Ia\n",
       "2   G_S      Ia\n",
       "3  Gb_L      Ia\n",
       "4   E_S      Ia"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord2index = {'PAD':0, 'START':1, 'END':2}\n",
    "for song in song_list:\n",
    "    curr_song = pd.read_csv('../recoded_songs/%s'%song)\n",
    "    chords = curr_song.state.values\n",
    "    for chord in chords:\n",
    "        if chord not in chord2index:\n",
    "            chord2index[chord] = len(chord2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chord2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2chord = {}\n",
    "for key, val in chord2index.items():\n",
    "    index2chord[val] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_progression(s, chord2index, padding_start=True):\n",
    "    enc = np.array([0,0,1] + [chord2index.get(w) for w in s] + [2])\n",
    "    return enc\n",
    "def get_progression(filepath):\n",
    "    song = pd.read_csv(filepath)\n",
    "    progression = song.state.values\n",
    "    return progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressionDataset(Dataset):\n",
    "    def __init__(self, song_paths, chord2index):\n",
    "        self.paths = song_paths\n",
    "        self.progressions = []\n",
    "        for path in self.paths:\n",
    "            progression = get_progression('../recoded_songs/%s'%path)\n",
    "            self.progressions.append(encode_progression(progression, chord2index))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.progressions[idx][:-1]\n",
    "        y = self.progressions[idx][1:]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ProgressionDataset(song_list, chord2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  1,  3,  4,  5,  6,  3,  3,  3,  7,  3,  4,  5,  6,  3,  3,  3,\n",
       "           7,  3,  4,  5,  6,  3,  4,  5,  6,  3,  4,  5,  6,  3,  3,  3,  7,  8,\n",
       "           9, 10, 11,  8,  8,  8, 12,  8,  9, 10, 11,  8,  8,  8, 12,  3,  4,  5,\n",
       "           6,  3,  4,  5,  6,  3,  4,  5,  6,  7,  8, 12,  7,  8, 12, 13,  7, 14,\n",
       "           8,  8, 12, 13,  7, 13,  7,  5, 15, 12, 14, 10, 10, 10, 10, 10, 10, 10,\n",
       "          14, 10, 10, 10, 10, 10, 14, 16, 15]]),\n",
       " tensor([[ 0,  1,  3,  4,  5,  6,  3,  3,  3,  7,  3,  4,  5,  6,  3,  3,  3,  7,\n",
       "           3,  4,  5,  6,  3,  4,  5,  6,  3,  4,  5,  6,  3,  3,  3,  7,  8,  9,\n",
       "          10, 11,  8,  8,  8, 12,  8,  9, 10, 11,  8,  8,  8, 12,  3,  4,  5,  6,\n",
       "           3,  4,  5,  6,  3,  4,  5,  6,  7,  8, 12,  7,  8, 12, 13,  7, 14,  8,\n",
       "           8, 12, 13,  7, 13,  7,  5, 15, 12, 14, 10, 10, 10, 10, 10, 10, 10, 14,\n",
       "          10, 10, 10, 10, 10, 14, 16, 15,  2]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelodyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MelodyRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, input_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.hidden = Variable(torch.zeros(1, 1, hidden_size))                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, self.hidden = self.gru(embedded, self.hidden)\n",
    "        output = self.out(self.hidden[-1])\n",
    "        return output, self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, optimizer,\n",
    "                teacher_forcing_ratio=0.5):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_size = y.size(0)\n",
    "    target_length = y.size(1)\n",
    "\n",
    "    output, hidden = model(x)\n",
    "\n",
    "    loss = 0\n",
    "    dec_input = y[:,0].unsqueeze(1) # always SOS\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(1, target_length):\n",
    "        output, hidden = model(dec_input)\n",
    "        yi =  y[:, di]\n",
    "        if (yi>0).sum() > 0:\n",
    "            # ignoring padding\n",
    "            loss += F.cross_entropy(output, yi, ignore_index = 0, reduction=\"sum\")/(yi>0).sum()\n",
    "        if use_teacher_forcing:\n",
    "            dec_input = y[:, di].unsqueeze(1)  # Teacher forcing: Feed the target as the next input\n",
    "        else:                \n",
    "            dec_input = output.argmax(dim=1).unsqueeze(1).detach()\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def train(model, dec_optimizer, epochs = 10,\n",
    "          teacher_forcing_ratio=0.5):\n",
    "    for i in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "        for x, y in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            loss = train_batch(x, y, model, dec_optimizer,\n",
    "                               teacher_forcing_ratio)\n",
    "            total_loss = loss*x.size(0)\n",
    "            total += x.size(0)\n",
    "            \n",
    "        print(\"train loss %.3f\" % (total_loss / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(chord2index)\n",
    "hidden_size = 100\n",
    "model = MelodyRNN(input_size, hidden_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 17.297\n",
      "train loss 9.372\n",
      "train loss 16.253\n",
      "train loss 8.189\n",
      "train loss 23.088\n",
      "train loss 7.817\n",
      "train loss 7.443\n",
      "train loss 6.846\n",
      "train loss 9.054\n",
      "train loss 13.585\n",
      "train loss 8.314\n",
      "train loss 8.633\n",
      "train loss 6.730\n",
      "train loss 16.933\n",
      "train loss 12.293\n",
      "train loss 8.134\n",
      "train loss 6.320\n",
      "train loss 14.737\n",
      "train loss 7.056\n",
      "train loss 13.105\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/eventbrite/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MelodyRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'Full_RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index2chord.pkl', 'wb') as f:\n",
    "    pkl.dump(index2chord, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
